<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="DESCRIPTION META TAG">
  <meta property="og:title" content="SOCIAL MEDIA TITLE TAG" />
  <meta property="og:description" content="SOCIAL MEDIA DESCRIPTION TAG TAG" />
  <meta property="og:url" content="URL OF THE WEBSITE" />
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/image/your_banner_image.png" />
  <meta property="og:image:width" content="1200" />
  <meta property="og:image:height" content="630" />


  <meta name="twitter:title" content="TWITTER BANNER TITLE META TAG">
  <meta name="twitter:description" content="TWITTER BANNER DESCRIPTION META TAG">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="static/images/your_twitter_banner_image.png">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="KEYWORDS SHOULD BE PLACED HERE">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>Evaluation of Habitat Robotics using Large Language Models</title>
  <link rel="icon" type="image/x-icon" href="static/images/favicon.png">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>

<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">Evaluation of Habitat Robotics using Large Language Models</h1>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              <span class="author-block">
                <a href="https://github.com/destin-v" target="_blank">William Li</a><sup>*</sup>,</span>
              <span class="author-block">
                <a href="https://www.linkedin.com/in/lei-hamilton-1746ba25" target="_blank">Lei
                  Hamilton</a><sup>*</sup>,</span>
              <a href="https://www.linkedin.com/in/kaise-alnatour-8342b6170" target="_blank">Kaise Al-natour</a>,</span>
              <a href="https://www.ll.mit.edu/biographies/sanjeev-mohindra" target="_blank">Sanjeev Mohindra</a></span>
            </div>

            <div class="is-size-5 publication-authors">
              <span class="author-block">MIT Lincoln Lab<br>IEEE HPEC 2025</span>
              <span class="eql-cntrb"><small><br><sup>*</sup>Indicates Equal Contribution</small></span>
            </div>

            <div class="column has-text-centered">
              <div class="publication-links">
                <!-- Arxiv PDF link -->
                <span class="link-block">
                  <a href="https://arxiv.org/pdf/2507.06157" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                    </span>
                    <span>Paper</span>
                  </a>
                </span>

                <!-- Github link -->
                <span class="link-block">
                  <a href="https://github.com/destin-v/benchmark-robotics-llm" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>

                <!-- ArXiv abstract Link -->
                <span class="link-block">
                  <a href="https://arxiv.org/abs/2507.06157" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="ai ai-arxiv"></i>
                    </span>
                    <span>arXiv</span>
                  </a>
                </span>
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>
  </section>


  <!-- Youtube video -->
  <section class="hero is-small is-light">
    <div class="hero-body">
      <div class="container">
        <!-- Paper video. -->
        <h2 class="title is-3">Habitat Simulator</h2>
        <div class="columns is-centered has-text-centered">
          <div class="column is-four-fifths">

            <div class="publication-video">
              <!-- Youtube embed code here -->
              <iframe src="https://www.youtube.com/embed/zJTmfgkvDjY" frameborder="0" allow="autoplay; encrypted-media"
                allowfullscreen></iframe>
            </div>
          </div>
        </div>
      </div>
    </div>
    <h2 class="subtitle has-text-centered">
      PARTNR provides a standardized baseline for evaluating planning, coordination, and perception for multiagent
      embodied robots in simulated indoor settings.
    </h2>
  </section>
  <!-- End youtube video -->


  <!-- Paper abstract -->
  <section class="section hero is-light">
    <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Abstract</h2>
          <div class="content has-text-justified">
            <p>
              This paper focuses on evaluating the effectiveness of Large Language Models at solving embodied robotic
              tasks using the Meta PARTNER benchmark. Meta PARTNR provides simplified environments and robotic
              interactions within randomized indoor kitchen scenes. Each randomized kitchen scene is given a task where
              two robotic agents cooperatively work together to solve the task. We evaluated multiple frontier models on
              Meta PARTNER environments. Our results indicate that reasoning models like OpenAI o3-mini outperform
              non-reasoning models like OpenAI GPT-4o and Llama 3 when operating in PARTNR's robotic embodied
              environments. o3-mini displayed outperform across centralized, decentralized, full observability, and
              partial observability configurations. This provides a promising avenue of research for embodied robotic
              development.
            </p>
          </div>
        </div>
      </div>
    </div>
  </section>
  <!-- End paper abstract -->


  <!-- Video carousel -->
  <section class="hero is-small">
    <div class="hero-body">
      <div class="container">
        <h2 class="title is-3">Experiment Videos</h2><br>
        <h3 class="title is-5">Left Panel:Spot Perspective ~ Right Panel:Humanoid Perspective</h3>
        <div id="results-carousel" class="carousel results-carousel">
          <div class="item item-video1">
            <video poster="" id="video1" autoplay controls muted loop height="100%" width="100%"">
            <!-- Your video file here -->
            <source src=" static/videos/video-episode_78_0.mp4" type="video/mp4">
            </video>
            <!-- Your video file here -->
            <img src="static/images/example1.png" alt="MY ALT TEXT"
              style='height: 100%; width: 100%; object-fit: contain' />
          </div>
          <div class="item item-video2">
            <video poster="" id="video2" autoplay controls muted loop height="100%" width="100%">
              <!-- Your video file here -->
              <source src="static/videos/video-episode_126_0.mp4" type="video/mp4">
            </video>
            <!-- Your video file here -->
            <img src="static/images/example2.png" alt="MY ALT TEXT"
              style='height: 100%; width: 100%; object-fit: contain' />

          </div>
          <div class="item item-video3">
            <video poster="" id="video3" autoplay controls muted loop height="100%" width="100%">\
              <!-- Your video file here -->
              <source src="static/videos/video-episode_127_0.mp4" type="video/mp4">
            </video>
            <!-- Your video file here -->
            <img src="static/images/example3.png" alt="MY ALT TEXT"
              style='height: 100%; width: 100%; object-fit: contain' />

          </div>
        </div>
      </div>
    </div>
  </section>
  <!-- End video carousel -->

  <!-- section -->
  <section class="section hero is-light">
    <div class="container">
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <div class="content has-text-justified">
            <!-- Your image here -->
            <img src="static/images/approach.png" alt="MY ALT TEXT"
              style='height: 100%; width: 100%; object-fit: contain' />
            <!-- Image description here -->
          </div>
        </div>
      </div>
    </div>
  </section>

  <!-- section -->
  <section class="section hero is-light">
    <div class="container">
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <div class="content has-text-justified">
            <!-- Your image here -->
            <img src="static/images/action_space.png" alt="MY ALT TEXT"
              style='height: 100%; width: 100%; object-fit: contain' />
            <!-- Image description here -->
          </div>
        </div>
      </div>
    </div>
  </section>

  <!-- section -->
  <section class="section hero is-light">
    <div class="container">
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <div class="content has-text-justified">
            <!-- Your image here -->
            <img src="static/images/example_state.png" alt="MY ALT TEXT"
              style='height: 100%; width: 100%; object-fit: contain' />
            <!-- Image description here -->
          </div>
        </div>
      </div>
    </div>
  </section>



  <!-- section -->
  <section class="section hero is-light">
    <div class="container">
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <div class="content has-text-justified">
            <!-- Your image here -->
            <img src="static/images/agent-architecture.png" alt="MY ALT TEXT"
              style='height: 100%; width: 100%; object-fit: contain' />
            <!-- Image description here -->
            <p>
              In the centralized planner, one planner controls the actions of both agents. The actions are sent to a
              low-level policy which mechanically performs the actions. These actions are then updated within the
              simulator (Habitat 3.0) and outputs a new state which is then observed individually by each agent. The
              observations update a shared world graph which is fed back into the centralized planner repeating the
              process. The decentralized planner in contrast has separate planners for each agent. In decentralized
              planning the agents have individual observations which are used to update a non-shared world graph.
            </p>
          </div>
        </div>
      </div>
    </div>
  </section>


  <!-- section -->
  <section class="section hero is-light">
    <div class="container">
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <div class="content has-text-justified">
            <!-- Your image here -->
            <img src="static/images/test_design.png" alt="MY ALT TEXT"
              style='height: 100%; width: 100%; object-fit: contain' />
            <!-- Image description here -->
          </div>
        </div>
      </div>
    </div>
  </section>

  <!-- section -->
  <section class="section hero is-light">
    <div class="container">

      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <div class="content has-text-justified">
            <!-- Your image here -->
            <img src="static/images/results.png" alt="MY ALT TEXT"
              style='height: 100%; width: 100%; object-fit: contain' />
            <!-- Image description here -->
            <p>
            <p>For each test case, we list the model under test, the planner type, the observability, and the metrics.
              We include a one sigma standard deviation for key metrics to show the variability.</p>
            <br>
            <p>Non-reasoning models such as GPT-4o and Llama 3 try to one-shot the problem and proceed. If the plan
              fails, the models need to replan. Non-reasoning models exhibit a lower percentage of completing their
              task, but they appear to complete them faster as shown in their sim steps. If we think about why this is,
              we know that non-reasoning models are faster and iterate more quickly. They are able to react to the
              simulation at a faster rate even if their actions have a lower success rate.</p>
            <br>
            <p>When we compare the non-reasoning models against a reasoning model such as o3-mini we see some
              interesting results. O3-mini has higher episode percentage completion across the board. We also see that
              each action taken by o3-mini has a higher success rate when compared to GPT-4o or Llama 3.1.
              Unfortunately, o3-mini takes longer to make a decision which results in longer sim steps. The trade-off of
              using reasoning models like o3-mini is that we pay a higher cost in sim steps for a better success rate
              and higher percentage of episode completion.</p>
            </p>
          </div>
        </div>
      </div>
    </div>
  </section>




  <!--BibTex citation -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>@inproceedings{Habitat-LLM-Benchmarks,
        author = {William Li and Lei Hamilton and Kaise Al-natour and Sanjeev Mohindra},
        title = {Evaluation of Habitat Robotics using Large Language Models},
        booktitle = {Institute of Electrical and Electronics Engineers (IEEE)},
        year = {2025}}
      </code></pre>
    </div>
  </section>
  <!--End BibTex citation -->


  <footer class="footer">
    <div class="container">
      <div class="columns is-centered">
        <div class="column is-8">
          <div class="content">

            <p>
              This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template"
                target="_blank">Academic Project Page Template</a> which was adopted from the <a
                href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
              You are free to borrow the source code of this website, we just ask that you link back to this page in the
              footer. <br> This website is licensed under a <a rel="license"
                href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
                Commons Attribution-ShareAlike 4.0 International License</a>.
            </p>

          </div>
        </div>
      </div>
    </div>
  </footer>

  <!-- Statcounter tracking code -->

  <!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

  <!-- End of Statcounter Code -->

</body>

</html>